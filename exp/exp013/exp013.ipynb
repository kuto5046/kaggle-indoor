{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.utilities.seed import seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1996"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# globals variable\n",
    "SEED = config['globals']['seed']\n",
    "MAX_EPOCHS = config['globals']['max_epochs']\n",
    "N_SPLITS = config['globals']['n_splits']\n",
    "USE_FOLDS = config['globals']['use_folds']\n",
    "DEBUG = config['globals']['debug']\n",
    "EXP_MESSAGE = config['globals']['exp_message']\n",
    "NOTES = config['globals']['notes']\n",
    "MODEL_SAVE = config['globals']['model_save']\n",
    "ONLY_PRED = config['globals']['only_pred']\n",
    "PRETRAINED = config['globals']['pretrained']\n",
    "PRETRAINED_PATH = config['globals']['pretrained_path']\n",
    "EXP_NAME = str(Path().resolve()).split('/')[-1]\n",
    "\n",
    "# seed\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exp013'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/user/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login 1bb2d0449c11d8b987e25c38b9d8dda176310fb6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypointを補正したdataset\n",
    "root_dir = Path('../../input/')\n",
    "train_df = pd.read_csv(root_dir/'kuto_wifi_dataset_v4/train/5000_10/train.csv')\n",
    "\n",
    "test_df = pd.read_csv(root_dir/'kuto_wifi_dataset_v4/test/5000_10/test.csv')\n",
    "\n",
    "sub_df = pd.read_csv('../../notebook/real_timestamp_sample_submission_v2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>path</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>file_name</th>\n",
       "      <th>floor</th>\n",
       "      <th>floor_str</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "      <td>-1</td>\n",
       "      <td>B1</td>\n",
       "      <td>114.335010</td>\n",
       "      <td>156.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466149574</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "      <td>-1</td>\n",
       "      <td>B1</td>\n",
       "      <td>106.659010</td>\n",
       "      <td>154.629520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466158395</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "      <td>-1</td>\n",
       "      <td>B1</td>\n",
       "      <td>102.168240</td>\n",
       "      <td>158.429080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466166621</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "      <td>-1</td>\n",
       "      <td>B1</td>\n",
       "      <td>107.850440</td>\n",
       "      <td>161.892620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580bb1506f2000638fc62</td>\n",
       "      <td>1578466886458</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580bb1506f2000638f...</td>\n",
       "      <td>-1</td>\n",
       "      <td>B1</td>\n",
       "      <td>41.316772</td>\n",
       "      <td>180.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74636</th>\n",
       "      <td>5dc8cea7659e181adb076a3f</td>\n",
       "      <td>5dcfb393878f3300066c70a6</td>\n",
       "      <td>1573892854685</td>\n",
       "      <td>5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...</td>\n",
       "      <td>6</td>\n",
       "      <td>F7</td>\n",
       "      <td>117.176710</td>\n",
       "      <td>99.235780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74637</th>\n",
       "      <td>5dc8cea7659e181adb076a3f</td>\n",
       "      <td>5dcfb393878f3300066c70a6</td>\n",
       "      <td>1573892859436</td>\n",
       "      <td>5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...</td>\n",
       "      <td>6</td>\n",
       "      <td>F7</td>\n",
       "      <td>122.269950</td>\n",
       "      <td>102.664960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74638</th>\n",
       "      <td>5dc8cea7659e181adb076a3f</td>\n",
       "      <td>5dcfb393878f3300066c70a6</td>\n",
       "      <td>1573892863738</td>\n",
       "      <td>5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...</td>\n",
       "      <td>6</td>\n",
       "      <td>F7</td>\n",
       "      <td>126.631090</td>\n",
       "      <td>107.011640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74639</th>\n",
       "      <td>5dc8cea7659e181adb076a3f</td>\n",
       "      <td>5dcfb393878f3300066c70a6</td>\n",
       "      <td>1573892868972</td>\n",
       "      <td>5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...</td>\n",
       "      <td>6</td>\n",
       "      <td>F7</td>\n",
       "      <td>131.792860</td>\n",
       "      <td>111.526085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74640</th>\n",
       "      <td>5dc8cea7659e181adb076a3f</td>\n",
       "      <td>5dcfb393878f3300066c70a6</td>\n",
       "      <td>1573892874306</td>\n",
       "      <td>5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...</td>\n",
       "      <td>6</td>\n",
       "      <td>F7</td>\n",
       "      <td>136.650040</td>\n",
       "      <td>116.407990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74641 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           site                      path      timestamp  \\\n",
       "0      5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "1      5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466149574   \n",
       "2      5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466158395   \n",
       "3      5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466166621   \n",
       "4      5a0546857ecc773753327266  5e1580bb1506f2000638fc62  1578466886458   \n",
       "...                         ...                       ...            ...   \n",
       "74636  5dc8cea7659e181adb076a3f  5dcfb393878f3300066c70a6  1573892854685   \n",
       "74637  5dc8cea7659e181adb076a3f  5dcfb393878f3300066c70a6  1573892859436   \n",
       "74638  5dc8cea7659e181adb076a3f  5dcfb393878f3300066c70a6  1573892863738   \n",
       "74639  5dc8cea7659e181adb076a3f  5dcfb393878f3300066c70a6  1573892868972   \n",
       "74640  5dc8cea7659e181adb076a3f  5dcfb393878f3300066c70a6  1573892874306   \n",
       "\n",
       "                                               file_name  floor floor_str  \\\n",
       "0      5a0546857ecc773753327266_5e1580d1f4c3420006d52...     -1        B1   \n",
       "1      5a0546857ecc773753327266_5e1580d1f4c3420006d52...     -1        B1   \n",
       "2      5a0546857ecc773753327266_5e1580d1f4c3420006d52...     -1        B1   \n",
       "3      5a0546857ecc773753327266_5e1580d1f4c3420006d52...     -1        B1   \n",
       "4      5a0546857ecc773753327266_5e1580bb1506f2000638f...     -1        B1   \n",
       "...                                                  ...    ...       ...   \n",
       "74636  5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...      6        F7   \n",
       "74637  5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...      6        F7   \n",
       "74638  5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...      6        F7   \n",
       "74639  5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...      6        F7   \n",
       "74640  5dc8cea7659e181adb076a3f_5dcfb393878f3300066c7...      6        F7   \n",
       "\n",
       "                x           y  \n",
       "0      114.335010  156.842240  \n",
       "1      106.659010  154.629520  \n",
       "2      102.168240  158.429080  \n",
       "3      107.850440  161.892620  \n",
       "4       41.316772  180.017100  \n",
       "...           ...         ...  \n",
       "74636  117.176710   99.235780  \n",
       "74637  122.269950  102.664960  \n",
       "74638  126.631090  107.011640  \n",
       "74639  131.792860  111.526085  \n",
       "74640  136.650040  116.407990  \n",
       "\n",
       "[74641 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>path</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9627</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9628</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9629</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9630</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9631</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>5e1580d1f4c3420006d520e4</td>\n",
       "      <td>1578466132778</td>\n",
       "      <td>5a0546857ecc773753327266_5e1580d1f4c3420006d52...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9632 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          site                      path      timestamp  \\\n",
       "0     5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "1     5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "2     5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "3     5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "4     5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "...                        ...                       ...            ...   \n",
       "9627  5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "9628  5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "9629  5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "9630  5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "9631  5a0546857ecc773753327266  5e1580d1f4c3420006d520e4  1578466132778   \n",
       "\n",
       "                                              file_name  \n",
       "0     5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "1     5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "2     5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "3     5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "4     5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "...                                                 ...  \n",
       "9627  5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "9628  5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "9629  5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "9630  5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "9631  5a0546857ecc773753327266_5e1580d1f4c3420006d52...  \n",
       "\n",
       "[9632 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象のsiteのみで実験\n",
    "target_site = '5a0546857ecc773753327266'\n",
    "train_df = train_df[train_df['site'] == target_site]\n",
    "test_df = test_df[test_df['site'] == target_site]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampleを取り出す\n",
    "EXT = '.npy'\n",
    "TRAIN_DATA_DIR = '../../input/kuto_wifi_dataset_v4/train/5000_10/' \n",
    "file_name = train_df['file_name'].sample(1).values[0]\n",
    "\n",
    "sample_file_path = TRAIN_DATA_DIR + file_name + EXT\n",
    "sample = np.load(sample_file_path)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"../../notebook/bssid_50.json\") as f:\n",
    "    bssid = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2838"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bssids = bssid[target_site]\n",
    "wifi_bssids_size = len(target_bssids)\n",
    "wifi_bssids_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ssid</th>\n",
       "      <th>bssid</th>\n",
       "      <th>bssid_x</th>\n",
       "      <th>bssid_y</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_samples_rssi_over_m50</th>\n",
       "      <th>n_samples_rssi_over_m55</th>\n",
       "      <th>n_samples_rssi_over_m60</th>\n",
       "      <th>n_samples_rssi_over_m65</th>\n",
       "      <th>n_samples_rssi_over_m70</th>\n",
       "      <th>site</th>\n",
       "      <th>floor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>c08ad78a45798cfe176a42b35c7381ae602711c5</td>\n",
       "      <td>220.011148</td>\n",
       "      <td>157.668275</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>ffc7c34369257431c7de9129094deb923bb3e3af</td>\n",
       "      <td>208.995536</td>\n",
       "      <td>156.881556</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>24d178b2fe580b871c853757e2c4668b16bc3ffc</td>\n",
       "      <td>230.002040</td>\n",
       "      <td>153.508576</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>23bfb8a3a2936f0536b7b8c1ee4a13706b8c18c6</td>\n",
       "      <td>204.576861</td>\n",
       "      <td>162.133758</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>059ea3d13de011f91587f1d176599605274f8ee8</td>\n",
       "      <td>170.015288</td>\n",
       "      <td>167.586402</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>ec46466c42df6238fbcae2b890eee2a012e54a02</td>\n",
       "      <td>7ff6dc072ab78c4ece184ec846d1f43f45c5c6c6</td>\n",
       "      <td>175.603702</td>\n",
       "      <td>79.293471</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>345fe449374546fd68b02b8e2f2ee4c4b0a5ec81</td>\n",
       "      <td>ad9070a00c25e44b2c0e2e495818c7b43e50828e</td>\n",
       "      <td>180.331317</td>\n",
       "      <td>44.985035</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553</th>\n",
       "      <td>809c2396be248fe8c23bca3a04a761294db2a95e</td>\n",
       "      <td>317edaf3ea5c9a9f4958556ab14e8cee1a611a56</td>\n",
       "      <td>153.047750</td>\n",
       "      <td>45.166750</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>4e3d9bf00149830025e0bcc7090f4f0ac059da8f</td>\n",
       "      <td>367750d787ec9c41106b733273b08d0a5b8046ae</td>\n",
       "      <td>150.634583</td>\n",
       "      <td>45.510945</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6555</th>\n",
       "      <td>2495e2a6499727dbb4b0ae3cac54bcb094a27b7b</td>\n",
       "      <td>b917a98c020924b26ea922b48c0d1632cea81ae3</td>\n",
       "      <td>139.332618</td>\n",
       "      <td>54.041437</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6556 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ssid  \\\n",
       "0     da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "1     da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "2     da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "3     da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "4     da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "...                                        ...   \n",
       "6551  ec46466c42df6238fbcae2b890eee2a012e54a02   \n",
       "6552  345fe449374546fd68b02b8e2f2ee4c4b0a5ec81   \n",
       "6553  809c2396be248fe8c23bca3a04a761294db2a95e   \n",
       "6554  4e3d9bf00149830025e0bcc7090f4f0ac059da8f   \n",
       "6555  2495e2a6499727dbb4b0ae3cac54bcb094a27b7b   \n",
       "\n",
       "                                         bssid     bssid_x     bssid_y  \\\n",
       "0     c08ad78a45798cfe176a42b35c7381ae602711c5  220.011148  157.668275   \n",
       "1     ffc7c34369257431c7de9129094deb923bb3e3af  208.995536  156.881556   \n",
       "2     24d178b2fe580b871c853757e2c4668b16bc3ffc  230.002040  153.508576   \n",
       "3     23bfb8a3a2936f0536b7b8c1ee4a13706b8c18c6  204.576861  162.133758   \n",
       "4     059ea3d13de011f91587f1d176599605274f8ee8  170.015288  167.586402   \n",
       "...                                        ...         ...         ...   \n",
       "6551  7ff6dc072ab78c4ece184ec846d1f43f45c5c6c6  175.603702   79.293471   \n",
       "6552  ad9070a00c25e44b2c0e2e495818c7b43e50828e  180.331317   44.985035   \n",
       "6553  317edaf3ea5c9a9f4958556ab14e8cee1a611a56  153.047750   45.166750   \n",
       "6554  367750d787ec9c41106b733273b08d0a5b8046ae  150.634583   45.510945   \n",
       "6555  b917a98c020924b26ea922b48c0d1632cea81ae3  139.332618   54.041437   \n",
       "\n",
       "      n_samples  n_samples_rssi_over_m50  n_samples_rssi_over_m55  \\\n",
       "0            52                       14                       14   \n",
       "1            25                        1                        5   \n",
       "2            11                        0                        0   \n",
       "3            47                        0                        1   \n",
       "4            65                        0                        4   \n",
       "...         ...                      ...                      ...   \n",
       "6551          7                        0                        0   \n",
       "6552         17                        0                        0   \n",
       "6553          5                        0                        0   \n",
       "6554         10                        0                        0   \n",
       "6555          5                        0                        0   \n",
       "\n",
       "      n_samples_rssi_over_m60  n_samples_rssi_over_m65  \\\n",
       "0                          14                       16   \n",
       "1                          13                       14   \n",
       "2                           0                        1   \n",
       "3                           4                        4   \n",
       "4                          10                       10   \n",
       "...                       ...                      ...   \n",
       "6551                        0                        0   \n",
       "6552                        3                       12   \n",
       "6553                        0                        0   \n",
       "6554                        0                        0   \n",
       "6555                        0                        0   \n",
       "\n",
       "      n_samples_rssi_over_m70                      site floor  \n",
       "0                          18  5a0546857ecc773753327266    B1  \n",
       "1                          14  5a0546857ecc773753327266    B1  \n",
       "2                           1  5a0546857ecc773753327266    B1  \n",
       "3                          17  5a0546857ecc773753327266    B1  \n",
       "4                          14  5a0546857ecc773753327266    B1  \n",
       "...                       ...                       ...   ...  \n",
       "6551                        7  5a0546857ecc773753327266    F4  \n",
       "6552                       17  5a0546857ecc773753327266    F4  \n",
       "6553                        5  5a0546857ecc773753327266    F4  \n",
       "6554                        3  5a0546857ecc773753327266    F4  \n",
       "6555                        0  5a0546857ecc773753327266    F4  \n",
       "\n",
       "[6556 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wifi_pos = pd.read_csv(f'../../input/nb013_bssid_position/nb013_bssid_position_{target_site}.csv')\n",
    "wifi_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bssid_x</th>\n",
       "      <th>bssid_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bssid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000840e5c600de293cea57f13326f273c86c3988</th>\n",
       "      <td>109.360597</td>\n",
       "      <td>103.353381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005246b6f51feb1a069e8f005d3e6aba2591b65b</th>\n",
       "      <td>31.989152</td>\n",
       "      <td>59.272956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0076ff7a084cb2ac8c146139965ab1be296e72c4</th>\n",
       "      <td>117.134146</td>\n",
       "      <td>111.699868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0089ad1dd75b13e2c3ceda344988c9f89a83a2f9</th>\n",
       "      <td>139.756293</td>\n",
       "      <td>89.002372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009a3ed672be7bd1b9c4437b43a53296771af098</th>\n",
       "      <td>31.747870</td>\n",
       "      <td>54.314438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff70d33df144bdc870f2fd804d713e3c430f1c9b</th>\n",
       "      <td>115.684780</td>\n",
       "      <td>104.532918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffa41c79865d7fb336f586e0dec8b080db1027fb</th>\n",
       "      <td>36.318478</td>\n",
       "      <td>121.153091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc7c34369257431c7de9129094deb923bb3e3af</th>\n",
       "      <td>208.995536</td>\n",
       "      <td>156.881556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe53bd4dcfaa42668baf5ea0d2ddc676538fce0</th>\n",
       "      <td>60.921142</td>\n",
       "      <td>59.771431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffedf27bf3bf8fa64d01e6b0a6affc9170716f1</th>\n",
       "      <td>66.313116</td>\n",
       "      <td>70.642202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2766 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             bssid_x     bssid_y\n",
       "bssid                                                           \n",
       "000840e5c600de293cea57f13326f273c86c3988  109.360597  103.353381\n",
       "005246b6f51feb1a069e8f005d3e6aba2591b65b   31.989152   59.272956\n",
       "0076ff7a084cb2ac8c146139965ab1be296e72c4  117.134146  111.699868\n",
       "0089ad1dd75b13e2c3ceda344988c9f89a83a2f9  139.756293   89.002372\n",
       "009a3ed672be7bd1b9c4437b43a53296771af098   31.747870   54.314438\n",
       "...                                              ...         ...\n",
       "ff70d33df144bdc870f2fd804d713e3c430f1c9b  115.684780  104.532918\n",
       "ffa41c79865d7fb336f586e0dec8b080db1027fb   36.318478  121.153091\n",
       "ffc7c34369257431c7de9129094deb923bb3e3af  208.995536  156.881556\n",
       "ffe53bd4dcfaa42668baf5ea0d2ddc676538fce0   60.921142   59.771431\n",
       "fffedf27bf3bf8fa64d01e6b0a6affc9170716f1   66.313116   70.642202\n",
       "\n",
       "[2766 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wifi_pos.groupby('bssid')[['bssid_x', 'bssid_y']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bssid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a52823c2ed57e18f81da316e5bcac8bd2754ce96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61a14256d195624aadd9dfd55c8643505635edd7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c93c29d2173b811a18de34940ccc210a3064230e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a09ab3d8a7700fec7b83389c06088c91748be41c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4cff1c8cfec27801ddc9a690ade87c57f1142ee0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>8553514711ebda556c2563b1ae2f3a6d4a2ba023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>6fbea29d369bf4483eea00f03f8fd4942f327a8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>166f82b0bfe87b860c471e1ff6ec201cddd3f0a9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>55c79013845087ab922af62ad08d981b7ead947c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>1cccae182f2dada388b4908829f72a10b220d8a6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         bssid\n",
       "0     a52823c2ed57e18f81da316e5bcac8bd2754ce96\n",
       "1     61a14256d195624aadd9dfd55c8643505635edd7\n",
       "2     c93c29d2173b811a18de34940ccc210a3064230e\n",
       "3     a09ab3d8a7700fec7b83389c06088c91748be41c\n",
       "4     4cff1c8cfec27801ddc9a690ade87c57f1142ee0\n",
       "...                                        ...\n",
       "2833  8553514711ebda556c2563b1ae2f3a6d4a2ba023\n",
       "2834  6fbea29d369bf4483eea00f03f8fd4942f327a8d\n",
       "2835  166f82b0bfe87b860c471e1ff6ec201cddd3f0a9\n",
       "2836  55c79013845087ab922af62ad08d981b7ead947c\n",
       "2837  1cccae182f2dada388b4908829f72a10b220d8a6\n",
       "\n",
       "[2838 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bssids_df = pd.DataFrame(target_bssids, columns=['bssid'])\n",
    "target_bssids_df\n",
    "# target_bssids_df.merge(wifi_pos.loc[:, ['bssid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2838"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bssids_df['bssid'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100., -100., -100., ..., -100., -100., -100.],\n",
       "       [-100., -100., -100., ..., -100., -100., -100.],\n",
       "       [-100., -100., -100., ..., -100., -100., -100.],\n",
       "       ...,\n",
       "       [-100., -100., -100., ..., -100., -100., -100.],\n",
       "       [-100., -100., -100., ..., -100., -100., -100.],\n",
       "       [-100., -100., -100., ..., -100., -100., -100.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(sample, copy=False, nan=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample / -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch model\n",
    "- embedding layerが重要  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IndoorDataset(Dataset):\n",
    "    def __init__(self, df, phase='train'):\n",
    "        self.df = df\n",
    "        self.phase = phase\n",
    "        self.file_name = df['file_name'].values\n",
    "\n",
    "        if phase in ['train', 'valid']:\n",
    "            # self.xy = df[['x', 'y']].values.astype(np.float32)\n",
    "            self.xy = df[['x', 'y']].values.astype(np.float32)  # wifiにより補正したx,yを使用\n",
    "            self.floor = df['floor'].values.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_name[idx]\n",
    "        feat = np.load(TRAIN_DATA_DIR + file_name + EXT)\n",
    "        np.nan_to_num(feat, copy=False, nan=-100)\n",
    "        feat = (feat / -100).astype(np.float32)\n",
    "        \n",
    "        if self.phase in ['train', 'valid']:\n",
    "            target = {\n",
    "                'xy':self.xy[idx],\n",
    "                'floor':self.floor[idx]\n",
    "            }\n",
    "        else:\n",
    "            target = {}\n",
    "        return feat, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_position_error(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n",
    "    return intermediate.sum()/xhat.shape[0]\n",
    "\n",
    "def to_np(input):\n",
    "    return input.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model: nn.Module, config: dict):\n",
    "    optimizer_config = config[\"optimizer\"]\n",
    "    optimizer_name = optimizer_config.get(\"name\")\n",
    "    base_optimizer_name = optimizer_config.get(\"base_name\")\n",
    "    optimizer_params = optimizer_config['params']\n",
    "\n",
    "    if hasattr(optim, optimizer_name):\n",
    "        optimizer = optim.__getattribute__(optimizer_name)(model.parameters(), **optimizer_params)\n",
    "        return optimizer\n",
    "    else:\n",
    "        base_optimizer = optim.__getattribute__(base_optimizer_name)\n",
    "        optimizer = globals().get(optimizer_name)(\n",
    "            model.parameters(), \n",
    "            base_optimizer,\n",
    "            **optimizer_config[\"params\"])\n",
    "        return  optimizer\n",
    "\n",
    "def get_scheduler(optimizer, config: dict):\n",
    "    scheduler_config = config[\"scheduler\"]\n",
    "    scheduler_name = scheduler_config.get(\"name\")\n",
    "\n",
    "    if scheduler_name is None:\n",
    "        return\n",
    "    else:\n",
    "        return optim.lr_scheduler.__getattribute__(scheduler_name)(\n",
    "            optimizer, **scheduler_config[\"params\"])\n",
    "\n",
    "\n",
    "def get_criterion(config: dict):\n",
    "    loss_config = config[\"loss\"]\n",
    "    loss_name = loss_config[\"name\"]\n",
    "    loss_params = {} if loss_config.get(\"params\") is None else loss_config.get(\"params\")\n",
    "    if hasattr(nn, loss_name):\n",
    "        criterion = nn.__getattribute__(loss_name)(**loss_params)\n",
    "    else:\n",
    "        criterion = globals().get(loss_name)(**loss_params)\n",
    "\n",
    "    return criterion\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner class(pytorch-lighting)\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.xy_criterion = get_criterion(config)\n",
    "        self.f_criterion = get_criterion(config)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self.model(x)\n",
    "        loss = self.xy_criterion(output[\"xy\"], y[\"xy\"])\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self.model(x)\n",
    "        xy_loss = self.xy_criterion(output[\"xy\"], y[\"xy\"])\n",
    "        f_loss = self.f_criterion(output[\"floor\"], y[\"floor\"])\n",
    "        loss = xy_loss  # + f_loss\n",
    "        mpe = mean_position_error(\n",
    "            to_np(output['xy'][:, 0]), to_np(output['xy'][:, 1]), 0, \n",
    "            to_np(y['xy'][:, 0]), to_np(y['xy'][:, 1]), 0)\n",
    "        \n",
    "        # floor lossは現状は無視して良い\n",
    "        self.log(f'Loss/val', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Loss/xy', xy_loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Loss/floor', f_loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'MPE/val', mpe, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = get_optimizer(self.model, self.config)\n",
    "        scheduler = get_scheduler(optimizer, self.config)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"Loss/val\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof\n",
    "def evaluate(model, loaders, phase):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    f_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loaders[phase]:\n",
    "            x, y = batch\n",
    "            output = model(x)\n",
    "            x_list.append(to_np(output['xy'][:, 0]))\n",
    "            y_list.append(to_np(output['xy'][:, 1]))\n",
    "            f_list.append(to_np(output['floor']))\n",
    "\n",
    "    x_list = np.concatenate(x_list)\n",
    "    y_list = np.concatenate(y_list)\n",
    "    f_list = np.concatenate(f_list)\n",
    "    return x_list, y_list, f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, wifi_bssids_size=2838, seq_length=19):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.wifi_bssids_size = wifi_bssids_size\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_norm1 = nn.BatchNorm1d(seq_length)\n",
    "        self.lstm1 = nn.LSTM(input_size=wifi_bssids_size,hidden_size=128,dropout=0.3, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128,hidden_size=16,dropout=0.1, batch_first=True)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc_xy = nn.Linear(16, 2)\n",
    "        self.fc_floor = nn.Linear(16, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input embedding\n",
    "        batch_size = x.shape[0]\n",
    "        # x = self.linear_layer(x)\n",
    "        \n",
    "        \n",
    "        # lstm layer\n",
    "        x = x.view(batch_size, self.seq_length, -1)  # [batch, 1]->[batch, 1, 1]\n",
    "        x = self.batch_norm1(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = torch.relu(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.pooling(x)\n",
    "        x = x.squeeze(2)\n",
    "        xy = self.fc_xy(x)\n",
    "        floor = torch.relu(self.fc_floor(x)).view(-1)\n",
    "        return {\"xy\": xy, \"floor\": floor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Fold 0\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkuto5046\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.26 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">happy-salad-313</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kuto5046/indoor\" target=\"_blank\">https://wandb.ai/kuto5046/indoor</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kuto5046/indoor/runs/25jr8jfu\" target=\"_blank\">https://wandb.ai/kuto5046/indoor/runs/25jr8jfu</a><br/>\n",
       "                Run data is saved locally in <code>/home/user/work/exp/exp013/wandb/run-20210415_212401-25jr8jfu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | model        | LSTMModel | 1.5 M \n",
      "1 | xy_criterion | MSELoss   | 0     \n",
      "2 | f_criterion  | MSELoss   | 0     \n",
      "-------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "6.116     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "oofs = []  # 全てのoofをdfで格納する\n",
    "predictions = []  # 全ての予測値をdfで格納する\n",
    "val_scores = []\n",
    "# skf = model_selection.StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "gkf = model_selection.GroupKFold(n_splits=N_SPLITS)\n",
    "train_fold = [(trn_idx, val_idx) for trn_idx, val_idx in gkf.split(train_df['path'], groups=train_df['path'])]\n",
    "# 今回はtargetを均等に分ける必要はなくpathが均等に分かれればいいのでskf.split()にpathを与えている。\n",
    "for fold in range(5):\n",
    "    # 指定したfoldのみループを回す\n",
    "    if fold not in USE_FOLDS:\n",
    "        continue\n",
    "\n",
    "    print('=' * 20)\n",
    "    print(f'Fold {fold}')\n",
    "    print('=' * 20)\n",
    "\n",
    "    # train/valid data\n",
    "    trn_idx, val_idx = train_fold[fold]\n",
    "    trn_df = train_df.loc[trn_idx, :].reset_index(drop=True)\n",
    "    val_df = train_df.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "    # data loader\n",
    "    loaders = {}\n",
    "    loader_config = config[\"loader\"]\n",
    "    loaders[\"train\"] = DataLoader(IndoorDataset(trn_df, phase=\"train\"), **loader_config[\"train\"], worker_init_fn=worker_init_fn) \n",
    "    loaders[\"valid\"] = DataLoader(IndoorDataset(val_df, phase=\"valid\"), **loader_config[\"valid\"], worker_init_fn=worker_init_fn)\n",
    "    loaders[\"test\"] = DataLoader(IndoorDataset(test_df, phase=\"test\"), **loader_config[\"test\"], worker_init_fn=worker_init_fn)\n",
    "\n",
    "    # model\n",
    "    model = LSTMModel()  # +1としているのはLEを1スタートで始めているため\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = []\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=f'Loss/val',\n",
    "        mode='min',\n",
    "        dirpath=f\"../../model/{EXP_NAME}\",\n",
    "        verbose=False,\n",
    "        filename=f'{model_name}-{fold}')\n",
    "    \n",
    "    if MODEL_SAVE:\n",
    "        callbacks.append(checkpoint_callback)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='Loss/val',\n",
    "        min_delta=0.00,\n",
    "        patience=200,\n",
    "        verbose=False,\n",
    "        mode='min')\n",
    "    callbacks.append(early_stop_callback)\n",
    "\n",
    "    # loggers\n",
    "    RUN_NAME = EXP_NAME + \"_\" + EXP_MESSAGE\n",
    "    wandb.init(project='indoor', notes=NOTES, entity='kuto5046', group=RUN_NAME)\n",
    "    wandb.run.name = RUN_NAME + f'-fold-{fold}'\n",
    "    wandb_config = wandb.config\n",
    "    wandb_config.model_name = model_name\n",
    "    wandb_config.LB = None\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    \n",
    "    loggers = []\n",
    "    loggers.append(WandbLogger())\n",
    "\n",
    "    learner = Learner(model, config)\n",
    "    # pretrained flag\n",
    "    if PRETRAINED:\n",
    "        ckpt = torch.load(PRETRAINED_PATH + f'{model_name}-{fold}.ckpt')\n",
    "        learner.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "    if not ONLY_PRED:\n",
    "        trainer = pl.Trainer(\n",
    "            logger=loggers, \n",
    "            callbacks=callbacks,\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            gpus=[0],\n",
    "            fast_dev_run=DEBUG,\n",
    "            deterministic=True,\n",
    "            # precision=16,\n",
    "            progress_bar_refresh_rate=0  # vscodeの時progress barの動作が遅いので表示しない\n",
    "            )\n",
    "\n",
    "        trainer.fit(learner, train_dataloader=loaders['train'], val_dataloaders=loaders['valid'])\n",
    "\n",
    "    #############\n",
    "    # validation (to make oof)\n",
    "    #############\n",
    "#     model.eval()  \n",
    "#     oof_df = train.loc[val_idx_for_train, ['timestamp', 'x', 'y', 'site_id','site_id_str', 'wifi_x','wifi_y', 'floor', 'floor_str', 'path', 'time_diff']].reset_index(drop=True)\n",
    "#     oof_x, oof_y, oof_f = evaluate(model, loaders, phase=\"valid\")\n",
    "#     oof_df[\"oof_x\"] = oof_x\n",
    "#     oof_df[\"oof_y\"] = oof_y\n",
    "#     oof_df[\"oof_floor\"] = oof_f\n",
    "#     oofs.append(oof_df)\n",
    "    \n",
    "#     val_score = mean_position_error(\n",
    "#         oof_df[\"oof_x\"].values, oof_df[\"oof_y\"].values, 0,\n",
    "#         oof_df['wifi_x'].values, oof_df['wifi_y'].values, 0)\n",
    "#     val_scores.append(val_score)\n",
    "#     print(f\"fold {fold}: mean position error {val_score}\")\n",
    "\n",
    "    #############\n",
    "    # inference\n",
    "    #############n\n",
    "\n",
    "#     preds_x, preds_y, preds_f = evaluate(model, loaders, phase=\"test\")\n",
    "#     test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n",
    "#     test_preds.columns = sub_df.columns\n",
    "#     test_preds[\"site_path_timestamp\"] = test[\"site_path_timestamp\"]\n",
    "#     test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n",
    "#     test_preds.to_csv(f'{EXP_NAME}_fold{fold}.csv', index=False)\n",
    "#     predictions.append(test_preds)\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1f7982fb43e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moofs_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moofs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moofs_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moofs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moofs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_path_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moofs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moofs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moofs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if len(USE_FOLDS) > 1:\n",
    "    oofs_df = pd.concat(oofs)\n",
    "else:\n",
    "    oofs_df = oofs[0]\n",
    "\n",
    "oofs_df['site_path_timestamp'] = oofs_df['site_id_str'].astype(str) + '_' + oofs_df['path'] + '_' + oofs_df['timestamp'].astype(str)\n",
    "oofs_df = oofs_df.sort_values('site_path_timestamp').reset_index(drop=True)\n",
    "oofs_df.to_csv(\"oof.csv\", index=False)\n",
    "oofs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint補正前のx,yでの評価\n",
    "oof_score = mean_position_error(\n",
    "    oofs_df['oof_x'], oofs_df['oof_y'], 0, \n",
    "    oofs_df['x'], oofs_df['y'], 0\n",
    "    )\n",
    "print(f\"CV:{oof_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint補正後のx,yでの評価\n",
    "oof_score = mean_position_error(\n",
    "    oofs_df['oof_x'], oofs_df['oof_y'], 0, \n",
    "    oofs_df['wifi_x'], oofs_df['wifi_y'], 0\n",
    "    )\n",
    "print(f\"CV:{oof_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testのwaypointを予測結果(wifi)から再度線形補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(USE_FOLDS) > 1:\n",
    "    # foldの結果を平均した後、reindexでsubmission fileにindexを合わせる\n",
    "    sub = pd.concat(predictions).groupby('site_path_timestamp').mean().reindex(sub_df.index)\n",
    "else:\n",
    "    sub = predictions[0].reindex(sub_df.index)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floorの数値を置換\n",
    "simple_accurate_99 = pd.read_csv(root_dir / 'simple-99-accurate-floor-model/submission.csv')\n",
    "sub['floor'] = simple_accurate_99['floor'].values\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../../\")\n",
    "from multiprocessing import Pool\n",
    "from src.io_f import read_data_file\n",
    "from scipy import interpolate\n",
    "\n",
    "# timestampとwaypointを元に線形補完しtarget_timestampに対応するtarget_waypointを求める　\n",
    "def wifi_waypoint_by_linear_interpolation(\n",
    "    observed_timestamp: np.ndarray, \n",
    "    observed_x:np.ndarray, \n",
    "    observed_y:np.ndarray, \n",
    "    target_timestamp:np.ndarray, \n",
    "    delta_time=500\n",
    "    ):\n",
    "    \"\"\"\n",
    "    observed: すでに知っている情報\n",
    "    observed-timestamp,x,yは全て同じ要素数となる\n",
    "\n",
    "    observedの情報からfitting関数を作成\n",
    "    \"\"\"\n",
    "    target_waypoint_list = []\n",
    "    num_interpolation = len(observed_timestamp) - 1  # 補完回数 \n",
    "    # 各waypoint間で線形補完\n",
    "    for i in range(num_interpolation):\n",
    "        # 潜在的なtimestampを作成(これのどれかにwifiを当てはめるような形)\n",
    "        n_split = int((max(observed_timestamp[i:i+2]) - min(observed_timestamp[i:i+2])) / delta_time) + 2  # delta_time刻みとなるように分割数を指定(+2は始点と終点分)\n",
    "        latent_timestamp = np.linspace(min(observed_timestamp[i:i+2]), max(observed_timestamp[i:i+2]), n_split).astype(int) \n",
    "        \n",
    "        # xが昇順の場合はlatentも昇順になるようにする\n",
    "        if observed_x[i] < observed_x[i+1]:\n",
    "            latent_x = np.linspace(min(observed_x[i:i+2]), max(observed_x[i:i+2]), n_split)\n",
    "        # xが降順の場合はlatentも降順になるようにする\n",
    "        else:\n",
    "            latent_x = np.linspace(min(observed_x[i:i+2]), max(observed_x[i:i+2]), n_split)[::-1]\n",
    "        \n",
    "        # 線形補完関数の適用\n",
    "        fitting_func = interpolate.interp1d(observed_x[i:i+2], observed_y[i:i+2])\n",
    "\n",
    "        # wifiのtimestampに最も近いものをsplit_timestampから取得しそれに対応するwaypointをwifiのwaypointとして取得\n",
    "        target_x = []\n",
    "        target_y = []\n",
    "\n",
    "        # 区間内のwifiデータのみ考える\n",
    "        if i == num_interpolation-1:\n",
    "            # pathの最後の区間にobserved timestampより未来にあるtimestampに対処\n",
    "            target_idx = min(observed_timestamp[i:i+2]) <= target_timestamp\n",
    "        elif i == 0:\n",
    "            # pathの最初の区間にobserved timestampより過去にあるtimestampに対処\n",
    "            target_idx = target_timestamp < max(observed_timestamp[i:i+2])\n",
    "        else:\n",
    "            target_idx = (min(observed_timestamp[i:i+2]) <= target_timestamp) & (target_timestamp < max(observed_timestamp[i:i+2]))\n",
    "        target_use_timestamp = target_timestamp[target_idx]\n",
    "\n",
    "        # timestampが最も近いものをtarget waypointとして取得\n",
    "        for t in target_use_timestamp:\n",
    "            idx = np.abs(latent_timestamp - t).argmin()  # targetとtimestampが最も近いものをlatentから取得\n",
    "            target_x.append(latent_x[idx])\n",
    "            # 原因はよくわからないがfittingするとnanが発生する場合がある\n",
    "            # その場合は元の値をそのまま使う\n",
    "            if np.isnan(fitting_func(latent_x[idx])).sum() > 0:\n",
    "                # print('yに欠損値あり')\n",
    "                idx = np.abs(observed_timestamp - t).argmin()  # \b0→wifiの最初のtimestampで問題が起きている\n",
    "                target_y.append(observed_y[idx])\n",
    "                \n",
    "            else:\n",
    "                target_y.append(fitting_func(latent_x[idx]))\n",
    "\n",
    "        assert len(target_x) == len(target_y)\n",
    "        target_waypoint = np.stack([target_x, target_y], axis=1)\n",
    "        target_waypoint_list.append(target_waypoint)\n",
    "\n",
    "    target_waypoint = np.concatenate(target_waypoint_list)\n",
    "    return target_waypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.merge(sub, on=\"site_path_timestamp\")\n",
    "test_df[\"path\"] = test_df[\"site_path_timestamp\"].str.split(\"_\", expand=True)[1]\n",
    "test_df[\"timestamp\"] = test_df[\"site_path_timestamp\"].str.split(\"_\", expand=True)[2]\n",
    "test_df['wifi_timestamp'] = test_df['timestamp'].astype(int) - test_df['time_diff']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 線形補完\n",
    "# path = test_df['path'].unique()[23]  #15\n",
    "# df = test_df[test_df['path']==path]\n",
    "\n",
    "# waypoint = wifi_waypoint_by_linear_interpolation(\n",
    "#     observed_timestamp=df['wifi_timestamp'].astype(int).values, \n",
    "#     observed_x=df['x'].values,\n",
    "#     observed_y=df['y'].values, \n",
    "#     target_timestamp=df['timestamp'].astype(int).values\n",
    "#     )\n",
    "# print(len(df), len(waypoint))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # print(df[\"timestamp\"].astype(int) - df[\"timestamp\"].astype(int).values[0])\n",
    "# plt.plot(df[\"x\"].values, df[\"y\"].values, ls='--', marker=\"o\", label='wifi')\n",
    "# plt.plot(waypoint[:,0], waypoint[:,1], ls='--', marker=\"o\", label='waypoint')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形補完でwaypointを修正\n",
    "waypoint_dfs = []\n",
    "for path,df in test_df.groupby('path'):  #15\n",
    "    tmp_waypoint = wifi_waypoint_by_linear_interpolation(\n",
    "        observed_timestamp=df['wifi_timestamp'].astype(int).values, \n",
    "        observed_x=df['x'].values,\n",
    "        observed_y=df['y'].values, \n",
    "        target_timestamp=df['timestamp'].astype(int).values\n",
    "        )\n",
    "    df['_x'] = tmp_waypoint[:,0]\n",
    "    df['_y'] = tmp_waypoint[:,1]\n",
    "    waypoint_dfs.append(df)\n",
    "\n",
    "waypoint_df = pd.concat(waypoint_dfs).reset_index(drop=True)\n",
    "waypoint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "(waypoint_df['x'] - waypoint_df['_x']).hist(label='x')\n",
    "(waypoint_df['y'] - waypoint_df['_y']).hist(label='y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.merge(waypoint_df[['site_path_timestamp', '_x', '_y']], on='site_path_timestamp').set_index('site_path_timestamp')\n",
    "sub = sub.drop(['x','y'], axis=1).rename(columns={'_x':'x', '_y':'y'})\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(EXP_NAME + '_sub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 後処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cost minimaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import scipy.interpolate\n",
    "import scipy.sparse\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from src.io_f import read_data_file\n",
    "from src import compute_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rel_positions(acce_datas, ahrs_datas):\n",
    "    step_timestamps, step_indexs, step_acce_max_mins = compute_f.compute_steps(acce_datas)\n",
    "    headings = compute_f.compute_headings(ahrs_datas)\n",
    "    stride_lengths = compute_f.compute_stride_length(step_acce_max_mins)\n",
    "    step_headings = compute_f.compute_step_heading(step_timestamps, headings)\n",
    "    rel_positions = compute_f.compute_rel_positions(stride_lengths, step_headings)\n",
    "    return rel_positions\n",
    "    \n",
    "def correct_path(args):\n",
    "    path, path_df = args\n",
    "    \n",
    "    T_ref  = path_df['timestamp'].values\n",
    "    xy_hat = path_df[['x', 'y']].values\n",
    "    \n",
    "    example = read_data_file(f'{root_dir}/indoor-location-navigation/test/{path}.txt')\n",
    "    rel_positions = compute_rel_positions(example.acce, example.ahrs)\n",
    "    if T_ref[-1] > rel_positions[-1, 0]:\n",
    "        rel_positions = [np.array([[0, 0, 0]]), rel_positions, np.array([[T_ref[-1], 0, 0]])]\n",
    "    else:\n",
    "        rel_positions = [np.array([[0, 0, 0]]), rel_positions]\n",
    "    rel_positions = np.concatenate(rel_positions)\n",
    "    \n",
    "    T_rel = rel_positions[:, 0]\n",
    "    delta_xy_hat = np.diff(scipy.interpolate.interp1d(T_rel, np.cumsum(rel_positions[:, 1:3], axis=0), axis=0)(T_ref), axis=0)\n",
    "\n",
    "    N = xy_hat.shape[0]\n",
    "    delta_t = np.diff(T_ref)\n",
    "    alpha = (8.1)**(-2) * np.ones(N)\n",
    "    beta  = (0.3 + 0.3 * 1e-3 * delta_t)**(-2)\n",
    "    A = scipy.sparse.spdiags(alpha, [0], N, N)\n",
    "    B = scipy.sparse.spdiags( beta, [0], N-1, N-1)\n",
    "    D = scipy.sparse.spdiags(np.stack([-np.ones(N), np.ones(N)]), [0, 1], N-1, N)\n",
    "\n",
    "    Q = A + (D.T @ B @ D)\n",
    "    c = (A @ xy_hat) + (D.T @ (B @ delta_xy_hat))\n",
    "    xy_star = scipy.sparse.linalg.spsolve(Q, c)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'site_path_timestamp' : path_df['site_path_timestamp'],\n",
    "        'floor' : path_df['floor'],\n",
    "        'x' : xy_star[:, 0],\n",
    "        'y' : xy_star[:, 1],\n",
    "    })\n",
    "\n",
    "def correct_path_train(args):\n",
    "    #print(args)\n",
    "    (site_id, path, floor), path_df = args\n",
    "    \n",
    "    T_ref  = path_df['timestamp'].values\n",
    "    xy_hat = path_df[['x', 'y']].values\n",
    "    \n",
    "    example = read_data_file(f'{root_dir}/indoor-location-navigation/train/{site_id}/{floor}/{path}.txt')\n",
    "    rel_positions = compute_rel_positions(example.acce, example.ahrs)\n",
    "    if T_ref[-1] > rel_positions[-1, 0]:\n",
    "        rel_positions = [np.array([[0, 0, 0]]), rel_positions, np.array([[T_ref[-1], 0, 0]])]\n",
    "    else:\n",
    "        rel_positions = [np.array([[0, 0, 0]]), rel_positions]\n",
    "    rel_positions = np.concatenate(rel_positions)\n",
    "    \n",
    "    T_rel = rel_positions[:, 0]\n",
    "\n",
    "    try:\n",
    "        delta_xy_hat = np.diff(scipy.interpolate.interp1d(T_rel, np.cumsum(rel_positions[:, 1:3], axis=0), axis=0)(T_ref), axis=0)\n",
    "    except:\n",
    "        return pd.DataFrame({\n",
    "            'site_path_timestamp' : path_df['site_path_timestamp'],\n",
    "            'floor' : path_df['floor'],\n",
    "            'x' : path_df['x'].to_numpy(),\n",
    "            'y' : path_df['y'].to_numpy()\n",
    "        })\n",
    "    \n",
    "\n",
    "    N = xy_hat.shape[0]\n",
    "    delta_t = np.diff(T_ref)\n",
    "    alpha = (8.1)**(-2) * np.ones(N)\n",
    "    beta  = (0.3 + 0.3 * 1e-3 * delta_t)**(-2)\n",
    "    A = scipy.sparse.spdiags(alpha, [0], N, N)\n",
    "    B = scipy.sparse.spdiags( beta, [0], N-1, N-1)\n",
    "    D = scipy.sparse.spdiags(np.stack([-np.ones(N), np.ones(N)]), [0, 1], N-1, N)\n",
    "\n",
    "    Q = A + (D.T @ B @ D)\n",
    "    c = (A @ xy_hat) + (D.T @ (B @ delta_xy_hat))\n",
    "    xy_star = scipy.sparse.linalg.spsolve(Q, c)\n",
    "\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'site_path_timestamp' : path_df['site_path_timestamp'],\n",
    "        'floor' : path_df['floor'],\n",
    "        'x' : xy_star[:, 0],\n",
    "        'y' : xy_star[:, 1],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "oofs_df = oofs_df.rename(columns={'x':'target_x', 'y':'target_y', 'oof_x':'x', 'oof_y':'y'})\n",
    "processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    dfs = pool.imap_unordered(correct_path_train, oofs_df.groupby(['site_id_str', 'path', 'floor_str']))\n",
    "    dfs = tqdm(dfs)\n",
    "    dfs = list(dfs)\n",
    "\n",
    "oof_post_process = pd.concat(dfs).sort_index()\n",
    "oofs_df['oof_min_x'] = oof_post_process['x']\n",
    "oofs_df['oof_min_y'] = oof_post_process['y']\n",
    "\n",
    "# 元に戻す\n",
    "oofs_df = oofs_df.rename(columns={'x':'oof_x', 'y':'oof_y'})\n",
    "oofs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint補正前のx,yでの評価\n",
    "oof_score_post_process = mean_position_error(\n",
    "    oofs_df['oof_min_x'], oofs_df['oof_min_y'], 0, \n",
    "    oofs_df['target_x'], oofs_df['target_y'], 0\n",
    "    )\n",
    "print(f\"(after cost-min) CV:{oof_score_post_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint補正後のx,yでの評価\n",
    "oof_score_post_process = mean_position_error(\n",
    "    oofs_df['oof_min_x'], oofs_df['oof_min_y'], 0, \n",
    "    oofs_df['wifi_x'], oofs_df['wifi_y'], 0\n",
    "    )\n",
    "print(f\"(after cost-min) CV:{oof_score_post_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_pred = oofs_df[\"oof_min_x\"]\n",
    "# y_pred = oofs_df[\"oof_min_y\"]\n",
    "# f_pred = oofs_df[\"floor\"]  # 正解を与える\n",
    "# x_true = oofs_df[\"wifi_x\"]\n",
    "# y_true = oofs_df[\"wifi_y\"]\n",
    "# f_true = oofs_df[\"floor\"]\n",
    "# site_arr = oofs_df[\"site_id_str\"]\n",
    "# df_result_site2 = calc_metrics_site(x_pred, y_pred, f_pred, x_true, y_true, f_true, site_arr)\n",
    "# df_result_site2.style.bar(subset=['n_sample', 'score'], color=['teal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_eval_report(df_result_site2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.reset_index()\n",
    "sub_org = sub.copy()\n",
    "tmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\n",
    "sub['site'] = tmp[0]\n",
    "sub['path'] = tmp[1]\n",
    "sub['timestamp'] = tmp[2].astype(float)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    dfs = pool.imap_unordered(correct_path, sub.groupby(['path']))\n",
    "    dfs = tqdm(dfs)\n",
    "    dfs = list(dfs)\n",
    "new_sub = pd.concat(dfs).sort_values('site_path_timestamp')\n",
    "new_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub.to_csv(RUN_NAME + '_cost_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## snap to grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "def sub_process(sub, train_waypoints):\n",
    "    train_waypoints['isTrainWaypoint'] = True\n",
    "    sub = split_col(sub[['site_path_timestamp','floor','x','y']]).copy()\n",
    "    sub = sub.merge(train_waypoints[['site','floorNo','floor']].drop_duplicates(), how='left')\n",
    "    sub = sub.merge(\n",
    "        train_waypoints[['x','y','site','floor','isTrainWaypoint']].drop_duplicates(),\n",
    "        how='left',\n",
    "        on=['site','x','y','floor']\n",
    "             )\n",
    "    sub['isTrainWaypoint'] = sub['isTrainWaypoint'].fillna(False)\n",
    "    return sub.copy()\n",
    "\n",
    "def split_col(df):\n",
    "    df = pd.concat([\n",
    "        df['site_path_timestamp'].str.split('_', expand=True) \\\n",
    "        .rename(columns={0:'site',\n",
    "                         1:'path',\n",
    "                         2:'timestamp'}),\n",
    "        df\n",
    "    ], axis=1).copy()\n",
    "    return df\n",
    "\n",
    "floor_map = {\"B2\":-2, \"B1\":-1, \"F1\":0, \"F2\": 1, \"F3\":2,\n",
    "             \"F4\":3, \"F5\":4, \"F6\":5, \"F7\":6,\"F8\":7,\"F9\":8,\n",
    "             \"1F\":0, \"2F\":1, \"3F\":2, \"4F\":3, \"5F\":4, \"6F\":5,\n",
    "             \"7F\":6, \"8F\": 7, \"9F\":8}\n",
    "\n",
    "def add_xy(df):\n",
    "    df['xy'] = [(x, y) for x,y in zip(df['x'], df['y'])]\n",
    "    return df\n",
    "\n",
    "def closest_point(point, points):\n",
    "    \"\"\" Find closest point from a list of points. \"\"\"\n",
    "    return points[cdist([point], points).argmin()]\n",
    "\n",
    "def snap_to_grid(sub, threshold):\n",
    "    \"\"\"\n",
    "    Snap to grid if within a threshold.\n",
    "    \n",
    "    x, y are the predicted points.\n",
    "    x_, y_ are the closest grid points.\n",
    "    _x_, _y_ are the new predictions after post processing.\n",
    "    \"\"\"\n",
    "    sub['_x_'] = sub['x']\n",
    "    sub['_y_'] = sub['y']\n",
    "    sub.loc[sub['dist'] < threshold, '_x_'] = sub.loc[sub['dist'] < threshold]['x_']\n",
    "    sub.loc[sub['dist'] < threshold, '_y_'] = sub.loc[sub['dist'] < threshold]['y_']\n",
    "    return sub.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waypoints = pd.read_csv('../../input/indoor-location-train-waypoints/train_waypoints.csv')\n",
    "snap_df = oofs_df[['site_path_timestamp','floor','oof_min_x','oof_min_y']].copy()\n",
    "snap_df = snap_df.rename(columns={'oof_min_x':'x', 'oof_min_y':'y'})\n",
    "# snap_df = oofs_df[['site_path_timestamp','floor','oof_x','oof_y']].copy()\n",
    "# snap_df = snap_df.rename(columns={'oof_x':'x', 'oof_y':'y'})\n",
    "snap_df = sub_process(snap_df, train_waypoints)\n",
    "snap_df = add_xy(snap_df)\n",
    "train_waypoints = add_xy(train_waypoints)\n",
    "\n",
    "ds = []\n",
    "for (site, myfloor), d in tqdm(snap_df.groupby(['site','floor'])):\n",
    "    true_floor_locs = train_waypoints.loc[(train_waypoints['floor'] == myfloor) &\n",
    "                                          (train_waypoints['site'] == site)] \\\n",
    "        .reset_index(drop=True)\n",
    "    if len(true_floor_locs) == 0:\n",
    "        print(f'Skipping {site} {myfloor}')\n",
    "        continue\n",
    "    d['matched_point'] = [closest_point(x, list(true_floor_locs['xy'])) for x in d['xy']]\n",
    "    d['oof_min_snap_x'] = d['matched_point'].apply(lambda x: x[0])\n",
    "    d['oof_min_snap_y'] = d['matched_point'].apply(lambda x: x[1])\n",
    "    ds.append(d)\n",
    "\n",
    "# 上書き\n",
    "snap_df = pd.concat(ds).sort_index()\n",
    "snap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs_df['oof_min_snap_x'] = snap_df['oof_min_snap_x']\n",
    "oofs_df['oof_min_snap_y'] = snap_df['oof_min_snap_y']\n",
    "oofs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint補正前のx,yでの評価\n",
    "oof_score_post_process = mean_position_error(\n",
    "    oofs_df['oof_min_snap_x'], oofs_df['oof_min_snap_y'], 0, \n",
    "    oofs_df['target_x'], oofs_df['target_y'], 0\n",
    "    )\n",
    "print(f\"(after cost-min + snap) CV:{oof_score_post_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint補正前のx,yでの評価\n",
    "oof_score_post_process = mean_position_error(\n",
    "    oofs_df['oof_min_snap_x'], oofs_df['oof_min_snap_y'], 0, \n",
    "    oofs_df['wifi_x'], oofs_df['wifi_y'], 0\n",
    "    )\n",
    "print(f\"(after cost-min + snap) CV:{oof_score_post_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# path = oofs_df[\"path\"].unique()[9] # \"5d10a1669c50c70008fe8977\"\n",
    "# tmp = oofs_df[oofs_df[\"path\"]==path].copy()\n",
    "# plt.plot(tmp[\"wifi_x\"], tmp[\"wifi_y\"], marker=\"o\", label=\"target\")\n",
    "# plt.plot(tmp[\"oof_x\"], tmp[\"oof_y\"], marker=\"o\", label=\"pred\")\n",
    "# window=int(len(tmp)/5)\n",
    "# plt.plot(tmp[\"oof_x\"].rolling(window,min_periods=1).mean(), tmp[\"oof_y\"].rolling(window,min_periods=1).mean(), marker=\"o\", label=\"smoothing\")\n",
    "# plt.legend()\n",
    "\n",
    "for path, df in oofs_df.groupby(\"path\"):\n",
    "    if len(df) >= 5:\n",
    "        window = int(len(df)/5)\n",
    "        oofs_df.loc[oofs_df[\"path\"]==path, \"oof_smoothing_x\"] = df[\"oof_min_snap_x\"].rolling(window, min_periods=1).mean()\n",
    "        oofs_df.loc[oofs_df[\"path\"]==path, \"oof_smoothing_y\"] = df[\"oof_min_snap_y\"].rolling(window, min_periods=1).mean()\n",
    "    else:\n",
    "        oofs_df.loc[oofs_df[\"path\"]==path, \"oof_smoothing_x\"] = df[\"oof_min_snap_x\"]\n",
    "        oofs_df.loc[oofs_df[\"path\"]==path, \"oof_smoothing_y\"] = df[\"oof_min_snap_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint補正後のx,yでの評価\n",
    "oof_score_post_process = mean_position_error(\n",
    "    oofs_df['oof_smoothing_x'], oofs_df['oof_smoothing_y'], 0, \n",
    "    oofs_df['wifi_x'], oofs_df['wifi_y'], 0\n",
    "    )\n",
    "print(f\"(after cost-min) CV:{oof_score_post_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_pred = oofs_df[\"oof_min_snap_x\"]\n",
    "# y_pred = oofs_df[\"oof_min_snap_y\"]\n",
    "# f_pred = oofs_df[\"floor\"]  # 正解を与える\n",
    "# x_true = oofs_df[\"wifi_x\"]\n",
    "# y_true = oofs_df[\"wifi_y\"]\n",
    "# f_true = oofs_df[\"floor\"]\n",
    "# site_arr = oofs_df[\"site_id_str\"]\n",
    "# df_result_site3 = calc_metrics_site(x_pred, y_pred, f_pred, x_true, y_true, f_true, site_arr)\n",
    "# df_result_site3.style.bar(subset=['n_sample', 'score'], color=['teal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_eval_report(df_result_site3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waypoints = pd.read_csv('../../input/indoor-location-train-waypoints/train_waypoints.csv')\n",
    "\n",
    "new_sub = sub_process(new_sub, train_waypoints)\n",
    "new_sub = add_xy(new_sub)\n",
    "train_waypoints = add_xy(train_waypoints)\n",
    "\n",
    "ds = []\n",
    "for (site, myfloor), d in new_sub.groupby(['site','floor']):\n",
    "    true_floor_locs = train_waypoints.loc[(train_waypoints['floor'] == myfloor) &\n",
    "                                          (train_waypoints['site'] == site)] \\\n",
    "        .reset_index(drop=True)\n",
    "    if len(true_floor_locs) == 0:\n",
    "        print(f'Skipping {site} {myfloor}')\n",
    "        continue\n",
    "    d['matched_point'] = [closest_point(x, list(true_floor_locs['xy'])) for x in d['xy']]\n",
    "    d['x_'] = d['matched_point'].apply(lambda x: x[0])\n",
    "    d['y_'] = d['matched_point'].apply(lambda x: x[1])\n",
    "    ds.append(d)\n",
    "\n",
    "new_sub2 = pd.concat(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub2.rename(columns=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub2 = new_sub2[['site_path_timestamp','floor','x_','y_']].sort_index()\n",
    "new_sub2 = new_sub2.rename(columns={'x_':'x', 'y_':'y'})\n",
    "new_sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub2.to_csv(RUN_NAME + '_cost_snap_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# df_result_site1['score'].plot(label='oof')\n",
    "# df_result_site2['score'].plot(label='cost')\n",
    "# df_result_site3['score'].plot(label='cost+snap')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.savefig('site_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
